{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先Filter 在2015/12 ~ 2018/12 存續的ETF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先開啟檔案位置，並設定初始時間作為篩選門檻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "#path = r'C:\\Users\\User\\Desktop\\ETF分組\\CURRENCY + PRE STOCK (第十五組)\\第15組'\n",
    "\n",
    "start_date = datetime.strptime( \"2016/01/01\" , \"%Y/%m/%d\")\n",
    "\n",
    "out_file =  open( r'C:\\Users\\User\\Documents\\GitHub\\HW1\\HW1\\data\\ETF List Filtered.csv', 'w',newline='')\n",
    "in_file1 = open( r'C:\\Users\\User\\Documents\\GitHub\\HW1\\HW1\\data\\Currency ETF List (36).csv', 'r') \n",
    "in_file2 = open( r'C:\\Users\\User\\Documents\\GitHub\\HW1\\HW1\\data\\Preferred Stock ETF List (12).csv', 'r')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用CSV庫\n",
    "## 用DictReader來讀取特定的行數，用法類似字典\n",
    "## 用writer來寫出檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reader = csv.DictReader(in_file1)\n",
    "csv_writer = csv.writer(out_file)\n",
    "csv_writer.writerow(['Symbol', 'ETF Name', 'Inception','Type']) #先寫出行名稱\n",
    "\n",
    "for a_row in csv_reader: #對每一列，進行Dictionary-like的讀取\n",
    "    symbol = a_row['Symbol']\n",
    "    etf_name = a_row['ETF Name']\n",
    "    inception = datetime.strptime( a_row['Inception'], \"%Y/%m/%d\") \n",
    "#寫入\n",
    "    if inception  <= start_date:\n",
    "        csv_writer.writerow([symbol, etf_name, inception.date(), 'Currency']) #寫出四行，分別是代號、名稱、創立時間、跟基金類型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reader2 = csv.DictReader(in_file2)\n",
    "for a_row in csv_reader2:\n",
    "    symbol = a_row['Symbol']\n",
    "    etf_name = a_row['ETF Name']\n",
    "    inception = datetime.strptime( a_row['Inception'], \"%Y/%m/%d\")\n",
    "#寫入\n",
    "    if inception  <= start_date:\n",
    "        csv_writer.writerow([symbol, etf_name, inception.date(), 'Prefered Stock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 記得關閉檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file.close()\n",
    "in_file1.close()\n",
    "in_file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取ETF淨值，爬取網站為ycharts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 由於該網頁需要帳號密碼，所以需要一組帳密來登入\n",
    "## 之後可以調用login函數來取得一個對話控制，此允許我們爬取基金淨值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import json\n",
    "import urllib3\n",
    "import time\n",
    "def login():\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    \n",
    "    email = \"satai1919@gmail.com\"\n",
    "    pas = \"FintechMl\"\n",
    "    LOGIN_URL = \"https://ycharts.com/login\"\n",
    "    \n",
    "    session = requests.session()\n",
    "    \n",
    "    result = session.get(LOGIN_URL)\n",
    "    tree = html.fromstring(result.text)\n",
    "    authenticity_token = list(set(tree.xpath('//input[@name=\"csrfmiddlewaretoken\"]/@value')))[0]\n",
    "    \n",
    "    payload = {\n",
    "        'username': email,\n",
    "        'password': pas,\n",
    "        'csrfmiddlewaretoken': authenticity_token\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7,ja;q=0.6,zh-CN;q=0.5,fr;q=0.4',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Content-Length': '142',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Cookie': '__utmc=69688216; __utmz=69688216.1552357223.1.1.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); hblid=JQ0XqOZqwIXsXwT51y8Lx0HAoArzb6aB; _okdetect=%7B%22token%22%3A%2215523572229710%22%2C%22proto%22%3A%22https%3A%22%2C%22host%22%3A%22ycharts.com%22%7D; olfsk=olfsk12322538568271435; _ok=1228-592-10-8601; hubspotutk=7cf8506f03419977c4be0b998e16b46e; __hssrc=1; _cb_ls=1; _cb=B56Z-XDKRC_SC1U7V5; 33e807c05af9078f6b2ed01ced5fc28d5c8f52f4=1; wcsid=dhJeybtiypg1EtEV1y8Lx0Harz6ZJ0AA; _okbk=cd4%3Dtrue%2Cvi5%3D0%2Cvi4%3D1552376476295%2Cvi3%3Dactive%2Cvi2%3Dfalse%2Cvi1%3Dfalse%2Ccd8%3Dchat%2Ccd6%3D0%2Ccd5%3Daway%2Ccd3%3Dfalse%2Ccd2%3D0%2Ccd1%3D0%2C; _okac=f0b90d7b5b31a4a193bbea257a02ab8a; _okla=1; __utma=69688216.990749136.1552357223.1552376476.1552379039.4; __hstc=165832289.7cf8506f03419977c4be0b998e16b46e.1552357225006.1552376478295.1552379041795.4; _cb_svref=null; csrftoken='+authenticity_token+'; ycsessionid=uualzce6xlp27stjyfdee97evws5ollz; __utmt=1; page_view_ctr=51; __utmb=69688216.46.10.1552379039; mp_bd6455515e9730c7dc2f008755a4ddfe_mixpanel=%7B%22distinct_id%22%3A%20%221696fb366da666-05b45b73c1e575-36657105-fa000-1696fb366db7e2%22%2C%22%24device_id%22%3A%20%221696fb366da666-05b45b73c1e575-36657105-fa000-1696fb366db7e2%22%2C%22%24search_engine%22%3A%20%22google%22%2C%22%24initial_referrer%22%3A%20%22https%3A%2F%2Fwww.google.com%2F%22%2C%22%24initial_referring_domain%22%3A%20%22www.google.com%22%2C%22__mps%22%3A%20%7B%7D%2C%22__mpso%22%3A%20%7B%7D%2C%22__mpus%22%3A%20%7B%7D%2C%22__mpa%22%3A%20%7B%7D%2C%22__mpu%22%3A%20%7B%7D%2C%22__mpr%22%3A%20%5B%5D%2C%22__mpap%22%3A%20%5B%5D%2C%22%24user_id%22%3A%20%221696fb366da666-05b45b73c1e575-36657105-fa000-1696fb366db7e2%22%7D; __hssc=165832289.42.1552379041795; _chartbeat2=.1552357225125.1552382317031.1.B8gGKsDfweQGDsM3n-BBKPGqB8ZxQ4.40; _oklv=1552382376998%2CdhJeybtiypg1EtEV1y8Lx0Harz6ZJ0AA',\n",
    "        'Host': 'ycharts.com',\n",
    "        'Origin': 'https://ycharts.com',\n",
    "        'Referer': 'https://ycharts.com/login',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "    }\n",
    "    \n",
    "    r = session.post(\"https://ycharts.com/login\", data=payload, headers = headers, verify=False)\n",
    "    \n",
    "    r.status_code\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我們先開啟之前篩選過後的ETF檔案，並準備一個輸出檔案\n",
    "## 並先寫入共三十七個行名稱: 2018/12~2015/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\Users\\User\\Documents\\GitHub\\HW1\\HW1\\data\\ETF List Filtered.csv\"\n",
    "inputfile = open(filename, \"r\")\n",
    "name = \"output.csv\"\n",
    "output = open(name, \"w+\", newline='')\n",
    "writer=csv.writer(output)\n",
    "#write first line(2018/12~2015/12)\n",
    "time_list=['']\n",
    "for i in range(2018,2015,-1):\n",
    "    for j in range(12,0,-1):\n",
    "        time_list.append(str(i)+'/'+str(j))\n",
    "time_list.append('2015/12')\n",
    "writer.writerow(time_list)\n",
    "\n",
    "a = inputfile.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接著對每個基金爬去目標網站\n",
    "## 爬取後有16個頁面，每個頁面的表格都需要用BeautifulSoup來存取出資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FXA done\n",
      "FXB done\n",
      "FXC done\n",
      "FXCH done\n",
      "FXE done\n",
      "FXY done\n",
      "FXSG done\n",
      "FXS done\n",
      "FXF done\n",
      "DBV done\n",
      "UDN done\n",
      "UUP done\n",
      "URR done\n",
      "DRR done\n",
      "CNY done\n",
      "INR done\n",
      "EUFX done\n",
      "ULE done\n",
      "YCL done\n",
      "CROC done\n",
      "EUO done\n",
      "YCS done\n",
      "USDU done\n",
      "BZF done\n",
      "CYB done\n",
      "CEW done\n",
      "FPE done\n",
      "SPFF done\n",
      "PGF done\n",
      "PGX done\n",
      "IPFF done\n",
      "PFF done\n",
      "PSK done\n",
      "PFXF done\n"
     ]
    }
   ],
   "source": [
    "for i in range(34):\n",
    "    a = inputfile.readline()\n",
    "    a = a.split(\",\")\n",
    "\n",
    "    session = login() #登錄網站\n",
    "    nav_dict=dict()    #{'2018 Dec.':[31,123.54]} (key是字串，value是list[day,nat])\n",
    "    for j in range(1,17): # 16 pages in total\n",
    "        url = \"https://ycharts.com/companies/\"+a[0]+\"/net_asset_value.json?endDate=12/31/2018&pageNum=\"+str(j)+\"&startDate=12/1/2015\"\n",
    "        reqs = session.get(url) \n",
    "        rj = json.loads(reqs.text)\n",
    "        to_deal = rj[\"data_table_html\"]  \n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(to_deal, 'lxml')  \n",
    "\n",
    "        #使用BeautifulSoup解析出table\n",
    "        col1 = soup.find_all('td',attrs={\"class\": \"col1\"})  \n",
    "        col2 = soup.find_all('td',attrs={\"class\": \"col2\"})\n",
    "        #print(col1[0].text.split())    #格式是這樣 ['Dec.', '31,', '2018']    一個list\n",
    "        #print(col2[0].text.strip())    #格式是這樣 '123.54' 一個字串並沒有多餘的符號\n",
    "\n",
    "        #將時間以及NAV處理好後照順序存入list裡面\n",
    "        date = [ col1[index].text.split() for index in range(len(col1)) ] \n",
    "        nav = [ col2[index].text.strip() for index in range(len(col2)) ]\n",
    "\n",
    "        #對爬取到的每個時間跑迴圈，找出每個月分最後一個交易日，以此找出該基金的月底淨值\n",
    "        for index in range(len(col1)):\n",
    "            month=date[index][2]+' '+date[index][0]\n",
    "            day=int(re.sub(',', ' ', date[index][1]))\n",
    "            if nav_dict.get(month)==None:\n",
    "                nav_dict[month]=[day,nav[index]]\n",
    "            elif day>nav_dict[month][0]:\n",
    "                nav_dict[month]=[day,nav[index]]\n",
    "                \n",
    "    #對第i個基金寫入該基金的名稱以及37個月的月底基金淨值\n",
    "    nav_list=[a[0]] \n",
    "    for item in list(nav_dict.values()):\n",
    "        nav_list.append(item[1])\n",
    "    writer.writerow(nav_list)\n",
    "    print(a[0],'done')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 關閉檔案\n",
    "inputfile.close()\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
