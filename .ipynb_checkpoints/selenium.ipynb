{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 導入selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義抓取首頁的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_home_page(symbol):\n",
    "    url = \"https://www.etf.com/\" + symbol\n",
    "    r = requests.get(url)\n",
    "    r.encoding = 'utf-8'\n",
    "    soup = bs(r.text, 'lxml')\t#'lxml'解析器\t優點速度快\n",
    "    pattern = soup.find('div',attrs={\"class\": \"field-content helplink\"}) #首頁鏈結放在該標籤之下\n",
    "    url2 = pattern.a['href']\n",
    "    return url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.invesco.com/portal/site/us/financial-professional/etfs/product-detail?productId=FXY&ticker=FXY&title=powershares-currencyshares-japanese-yen-trust'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_home_page('FXY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接著需要知道每個基金公司把NAV淨值放在何處，以便我們用Selenium來點取下載鏈接\n",
    "## 這部份靠人工去尋找，接下來只需要利用Katalon Recoder 來生成python 指令即可\n",
    "## 先產生csv file reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "path = 'ETF List Filtered.csv'\n",
    "in_file =  open( path , 'r')\n",
    "csv_reader = csv.DictReader(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果有些下載鍵結可以用pandas直接打開，或者用requests下載，那就省去一個步驟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol FXA is done.\n",
      "Symbol FXB is done.\n",
      "Symbol FXC is done.\n",
      "Symbol FXCH is done.\n",
      "Symbol FXE is done.\n",
      "Symbol FXY is done.\n",
      "Symbol FXSG is done.\n",
      "Symbol FXS is done.\n",
      "Symbol FXF is done.\n",
      "Symbol DBV is done.\n",
      "Symbol UDN is done.\n",
      "Symbol UUP is done.\n",
      "Symbol URR is done.\n",
      "Symbol DRR is done.\n",
      "Symbol CNY is done.\n",
      "Symbol INR is done.\n",
      "Symbol EUFX is done.\n",
      "Symbol ULE is done.\n",
      "Symbol YCL is done.\n",
      "Symbol CROC is done.\n",
      "Symbol EUO is done.\n",
      "Symbol YCS is done.\n",
      "Symbol USDU is done.\n",
      "Symbol BZF is done.\n",
      "Symbol CYB is done.\n",
      "Symbol CEW is done.\n",
      "Symbol FPE is done.\n",
      "Symbol SPFF is done.\n",
      "Symbol PGF is done.\n",
      "Symbol PGX is done.\n",
      "Symbol IPFF is done.\n",
      "Symbol PFF is done.\n",
      "Symbol PSK is done.\n",
      "Symbol PFXF is done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "for a_row in csv_reader:\n",
    "    symbol = a_row['Symbol']\n",
    "    etf_name = a_row['ETF Name']\n",
    "    company_name = etf_name.split()[0]\n",
    "    if company_name == 'Invesco':  #如果基金公司是Invesco，那下載鏈結為id = downloadNavHistory\n",
    "        url = get_home_page(symbol)\n",
    "        driver.get(url)\n",
    "        driver.find_element_by_id(\"downloadNavHistory\").click()\n",
    "    elif company_name == 'Market': ##如果基金公司是Market Vectors，可直接用網址加代號取得檔案\n",
    "        driver.get('https://www.marketvectorsetns.com/HistoPriceExport.aspx?ticker=' + symbol)\n",
    "        \n",
    "    elif company_name == 'ProShares': ##如果基金公司是ProShares，可直接用網址加代號取得CSV檔案  \n",
    "        url = 'https://accounts.profunds.com/etfdata/ByFund/' + symbol +'-historical_nav.csv'\n",
    "        df = pd.read_csv(url)\n",
    "        df.to_csv( 'C:\\\\Users\\\\User\\\\Downloads\\\\%s.csv' %symbol)\n",
    "        \n",
    "    elif company_name == 'WisdomTree': ##如果基金公司是WisdomTree，得先進去一個網址後用beautifulsoup以及pandas來處理網站表格\n",
    "        homepage = 'https://www.wisdomtree.com/etfs/currency/'+ symbol.lower()\n",
    "        r = requests.get(homepage)\n",
    "        r.encoding = 'utf-8'\n",
    "        soup = bs(r.text, 'lxml')\n",
    "        pattern = soup.find('ul',attrs={\"class\": \"footer-links\"}) \n",
    "        table_html = pattern.a['data-href']\n",
    "\n",
    "        r = requests.get(table_html)\n",
    "        html_df = pd.read_html(r.text)\n",
    "        html_df[0].to_csv( 'C:\\\\Users\\\\User\\\\Downloads\\\\%s.csv' %symbol)\n",
    "    elif company_name == 'SPDR': ##如果基金公司是SPDR，得先進去一個網址後用beautifulsoup以及pandas來處理網站表格\n",
    "        driver.get('https://us.spdrs.com/site-content/xls/PSK_HistoricalNav.xls?fund=' + symbol)\n",
    "        \n",
    "    else:#其他基金公司 必須從yahoo來爬取\n",
    "        url = 'https://finance.yahoo.com/quote/' + symbol + \"/history?period1=1448899200&period2=1546272000&interval=1d&filter=history&frequency=1d\"\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, \"(.//*[normalize-space(text()) and normalize-space(.)='Currency in USD'])[1]/following::span[2]\")))\n",
    "        driver.find_element_by_xpath(\"(.//*[normalize-space(text()) and normalize-space(.)='Currency in USD'])[1]/following::span[2]\").click()\n",
    "    print('Symbol %s is done.' %symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接著我們要合併這些檔案，在此之前，一個簡單的例子來說明如何合併dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FXY  FXA\n",
      "12/1   23  233\n",
      "12/2   24  234\n",
      "12/3   22  322\n"
     ]
    }
   ],
   "source": [
    "dict1 ={'12/1' : 23, '12/2': 24, '12/3': 22} \n",
    "dict2 ={'12/1' : 233, '12/2': 234, '12/3': 322} \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame.from_dict(dict1, orient='index',  columns=['FXY'])\n",
    "df2 = pd.DataFrame.from_dict(dict2, orient='index',  columns=['FXA'])\n",
    "\n",
    "res = pd.concat([df1, df2], axis=1)\n",
    "print( res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先找到檔案資料夾，並找出所有剛剛下載的檔案的檔名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BZF.csv', 'CEW.csv', 'CROC.csv', 'CYB.csv', 'EUFX.csv', 'EUO.csv', 'FPE.csv', 'historical_navs_DBV_1552797335902.csv', 'historical_navs_FXA_1552797302307.csv', 'historical_navs_FXB_1552797305703.csv', 'historical_navs_FXCH_1552797313630.csv', 'historical_navs_FXC_1552797310008.csv', 'historical_navs_FXE_1552797317332.csv', 'historical_navs_FXF_1552797332125.csv', 'historical_navs_FXSG_1552797324760.csv', 'historical_navs_FXS_1552797328470.csv', 'historical_navs_FXY_1552797320997.csv', 'historical_navs_pgf_1552797398016.csv', 'historical_navs_pgx_1552797402471.csv', 'historical_navs_UDN_1552797339536.csv', 'historical_navs_UUP_1552797343168.csv', 'IPFF.csv', 'PFF.csv', 'PFXF.csv', 'SPFF.csv', 'ULE.csv', 'USDU.csv', 'YCL.csv', 'YCS.csv']\n",
      "['CNY_asof_20190317.xls', 'DRR_asof_20190317.xls', 'INR_asof_20190317.xls', 'PSK_HistoricalNav.xls', 'URR_asof_20190317.xls']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "path = r'C:\\Users\\User\\data'\t#the path where you put your downloaded files\n",
    "extension1 = 'csv'\n",
    "extension2 = 'xls'\n",
    "os.chdir(path)\n",
    "csv_list = [i for i in glob.glob('*.{}'.format(extension1))]\n",
    "excel_list = [i for i in glob.glob('*.{}'.format(extension2))]\n",
    "print(csv_list)\n",
    "print(excel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先看一下excel檔案 如何處理\n",
    "## 注意!! 有些檔案無法用read_excel讀取，必須要read_html來讀取，否則會出錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNY_asof_20190317.xls\n",
      "           0              1\n",
      "0       Date          Price\n",
      "1  3/15/2019  44.8950000000\n",
      "2  3/14/2019  44.6000000000\n",
      "3  3/13/2019  44.2893000000\n",
      "4  3/12/2019  44.4300000000\n",
      "DRR_asof_20190317.xls\n",
      "           0              1\n",
      "0       Date          Price\n",
      "1  3/15/2019  59.7750000000\n",
      "2  3/14/2019  61.0100000000\n",
      "3  3/13/2019  60.4250000000\n",
      "4  3/12/2019  59.8450000000\n",
      "INR_asof_20190317.xls\n",
      "           0              1\n",
      "0       Date          Price\n",
      "1  3/15/2019  42.9999000000\n",
      "2  3/14/2019  42.3950000000\n",
      "3  3/13/2019  41.5100000000\n",
      "4  3/12/2019  41.0500000000\n",
      "PSK_HistoricalNav.xls\n",
      "          Date        Nav\n",
      "0  14-Mar-2019  42.534408\n",
      "1  13-Mar-2019  42.472707\n",
      "2  12-Mar-2019  42.383852\n",
      "3  11-Mar-2019  42.334389\n",
      "4  08-Mar-2019  42.357835\n",
      "URR_asof_20190317.xls\n",
      "           0              1\n",
      "0       Date          Price\n",
      "1  3/15/2019  16.5500000000\n",
      "2  3/14/2019  16.5500000000\n",
      "3  3/13/2019  16.5500000000\n",
      "4  3/12/2019  16.5500000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in excel_list:\n",
    "\tprint(file)\n",
    "\ttry:\n",
    "\t\tdf = pd.read_html(path + '\\\\' +file, skiprows=1)[0].iloc[:, 0:2]\n",
    "\t\tprint(df.head())\n",
    "\texcept:\n",
    "\t\tdf = pd.read_excel(path + '\\\\' +file, skiprows=3).iloc[:, 0:2]\n",
    "\t\tprint(df.head())\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看一下csv如何處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BZF.csv ['Unnamed: 0', 'Date', 'Nav', 'Mid Bid/Ask', 'P/D to NAV', 'P/D Indicator']\n",
      "CEW.csv ['Unnamed: 0', 'Date', 'Nav', 'Mid Bid/Ask', 'P/D to NAV', 'P/D Indicator']\n",
      "CROC.csv ['Unnamed: 0', 'Date', 'ProShares Name', 'Ticker', 'NAV', 'Prior NAV', 'NAV Change (%)', 'NAV Change ($)', 'Shares Outstanding (000)', 'Assets Under Management']\n",
      "CYB.csv ['Unnamed: 0', 'Date', 'Nav', 'Mid Bid/Ask', 'P/D to NAV', 'P/D Indicator']\n",
      "EUFX.csv ['Unnamed: 0', 'Date', 'ProShares Name', 'Ticker', 'NAV', 'Prior NAV', 'NAV Change (%)', 'NAV Change ($)', 'Shares Outstanding (000)', 'Assets Under Management']\n",
      "EUO.csv ['Unnamed: 0', 'Date', 'ProShares Name', 'Ticker', 'NAV', 'Prior NAV', 'NAV Change (%)', 'NAV Change ($)', 'Shares Outstanding (000)', 'Assets Under Management']\n",
      "FPE.csv ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
      "historical_navs_DBV_1552797335902.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXA_1552797302307.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXB_1552797305703.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXCH_1552797313630.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXC_1552797310008.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXE_1552797317332.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXF_1552797332125.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXSG_1552797324760.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXS_1552797328470.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_FXY_1552797320997.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_pgf_1552797398016.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_pgx_1552797402471.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_UDN_1552797339536.csv ['Ticker', 'NAV', 'Date']\n",
      "historical_navs_UUP_1552797343168.csv ['Ticker', 'NAV', 'Date']\n",
      "IPFF.csv ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
      "PFF.csv ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
      "PFXF.csv ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
      "SPFF.csv ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
      "ULE.csv ['Unnamed: 0', 'Date', 'ProShares Name', 'Ticker', 'NAV', 'Prior NAV', 'NAV Change (%)', 'NAV Change ($)', 'Shares Outstanding (000)', 'Assets Under Management']\n",
      "USDU.csv ['Unnamed: 0', 'Date', 'Nav', 'Mid Bid/Ask', 'P/D to NAV', 'P/D Indicator']\n",
      "YCL.csv ['Unnamed: 0', 'Date', 'ProShares Name', 'Ticker', 'NAV', 'Prior NAV', 'NAV Change (%)', 'NAV Change ($)', 'Shares Outstanding (000)', 'Assets Under Management']\n",
      "YCS.csv ['Unnamed: 0', 'Date', 'ProShares Name', 'Ticker', 'NAV', 'Prior NAV', 'NAV Change (%)', 'NAV Change ($)', 'Shares Outstanding (000)', 'Assets Under Management']\n"
     ]
    }
   ],
   "source": [
    "for file in csv_list:\n",
    "\tdf = pd.read_csv(path + '\\\\' +file)\n",
    "\tcol_name = list(df.columns.values)\n",
    "\tprint(file, col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有些檔案的NAV 是寫作 'Nav' 或者 'Adj Close'，需要注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BZF.csv\n",
      "         Date      Nav\n",
      "0  03/14/2019  16.5367\n",
      "1  03/13/2019  16.5789\n",
      "2  03/12/2019  16.6396\n",
      "3  03/11/2019  16.4877\n",
      "4  03/08/2019  16.4171\n",
      "CEW.csv\n",
      "         Date      Nav\n",
      "0  03/15/2019  18.4994\n",
      "1  03/14/2019  18.4505\n",
      "2  03/13/2019  18.4614\n",
      "3  03/12/2019  18.4708\n",
      "4  03/11/2019  18.4207\n",
      "CROC.csv\n",
      "         Date        NAV\n",
      "0  03/15/2019  54.627192\n",
      "1  03/14/2019  54.936440\n",
      "2  03/13/2019  54.472166\n",
      "3  03/12/2019  54.639856\n",
      "4  03/11/2019  54.862680\n",
      "CYB.csv\n",
      "         Date      Nav\n",
      "0  03/15/2019  26.0629\n",
      "1  03/14/2019  26.0879\n",
      "2  03/13/2019  26.1014\n",
      "3  03/12/2019  26.0751\n",
      "4  03/11/2019  26.0375\n",
      "EUFX.csv\n",
      "         Date        NAV\n",
      "0  03/15/2019  43.940353\n",
      "1  03/14/2019  44.007569\n",
      "2  03/13/2019  43.876602\n",
      "3  03/12/2019  44.017162\n",
      "4  03/11/2019  44.205642\n",
      "EUO.csv\n",
      "         Date        NAV\n",
      "0  03/15/2019  25.135626\n",
      "1  03/14/2019  25.215577\n",
      "2  03/13/2019  25.070370\n",
      "3  03/12/2019  25.228045\n",
      "4  03/11/2019  25.448762\n",
      "FPE.csv\n",
      "         Date  Adj Close\n",
      "0  2015-11-30  15.811456\n",
      "1  2015-12-01  15.811456\n",
      "2  2015-12-02  15.811456\n",
      "3  2015-12-03  15.811456\n",
      "4  2015-12-04  15.803141\n",
      "historical_navs_DBV_1552797335902.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  24.53\n",
      "1  03/16/2019  24.53\n",
      "2  03/15/2019  24.53\n",
      "3  03/13/2019  24.58\n",
      "4  03/12/2019  24.63\n",
      "historical_navs_FXA_1552797302307.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  70.90\n",
      "1  03/16/2019  70.90\n",
      "2  03/15/2019  70.90\n",
      "3  03/14/2019  70.62\n",
      "4  03/13/2019  70.89\n",
      "historical_navs_FXB_1552797305703.csv\n",
      "         Date     NAV\n",
      "0  03/17/2019  128.77\n",
      "1  03/16/2019  128.77\n",
      "2  03/15/2019  128.77\n",
      "3  03/14/2019  128.83\n",
      "4  03/13/2019  128.29\n",
      "historical_navs_FXCH_1552797313630.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  72.84\n",
      "1  03/16/2019  72.84\n",
      "2  03/15/2019  72.84\n",
      "3  03/14/2019  72.74\n",
      "4  03/13/2019  72.91\n",
      "historical_navs_FXC_1552797310008.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  73.99\n",
      "1  03/16/2019  73.99\n",
      "2  03/15/2019  73.99\n",
      "3  03/14/2019  74.11\n",
      "4  03/13/2019  74.10\n",
      "historical_navs_FXE_1552797317332.csv\n",
      "         Date     NAV\n",
      "0  03/17/2019  108.06\n",
      "1  03/16/2019  108.06\n",
      "2  03/15/2019  108.06\n",
      "3  03/14/2019  107.86\n",
      "4  03/13/2019  107.91\n",
      "historical_navs_FXF_1552797332125.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  92.78\n",
      "1  03/16/2019  92.78\n",
      "2  03/15/2019  92.78\n",
      "3  03/14/2019  92.63\n",
      "4  03/13/2019  92.61\n",
      "historical_navs_FXSG_1552797324760.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  72.69\n",
      "1  03/16/2019  72.69\n",
      "2  03/15/2019  72.69\n",
      "3  03/14/2019  72.52\n",
      "4  03/13/2019  72.65\n",
      "historical_navs_FXS_1552797328470.csv\n",
      "         Date     NAV\n",
      "0  03/17/2019  100.95\n",
      "1  03/16/2019  100.95\n",
      "2  03/15/2019  100.95\n",
      "3  03/14/2019  100.18\n",
      "4  03/13/2019  100.31\n",
      "historical_navs_FXY_1552797320997.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  85.49\n",
      "1  03/16/2019  85.49\n",
      "2  03/15/2019  85.49\n",
      "3  03/14/2019  85.38\n",
      "4  03/13/2019  85.76\n",
      "historical_navs_pgf_1552797398016.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  18.43\n",
      "1  03/16/2019  18.43\n",
      "2  03/15/2019  18.43\n",
      "3  03/13/2019  18.40\n",
      "4  03/12/2019  18.36\n",
      "historical_navs_pgx_1552797402471.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  14.53\n",
      "1  03/16/2019  14.53\n",
      "2  03/15/2019  14.53\n",
      "3  03/13/2019  14.49\n",
      "4  03/12/2019  14.46\n",
      "historical_navs_UDN_1552797339536.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  20.87\n",
      "1  03/16/2019  20.87\n",
      "2  03/15/2019  20.87\n",
      "3  03/13/2019  20.88\n",
      "4  03/12/2019  20.79\n",
      "historical_navs_UUP_1552797343168.csv\n",
      "         Date    NAV\n",
      "0  03/17/2019  25.80\n",
      "1  03/16/2019  25.80\n",
      "2  03/15/2019  25.80\n",
      "3  03/13/2019  25.77\n",
      "4  03/12/2019  25.87\n",
      "IPFF.csv\n",
      "         Date  Adj Close\n",
      "0  2015-11-30  14.132353\n",
      "1  2015-12-01  14.031088\n",
      "2  2015-12-02  14.022507\n",
      "3  2015-12-03  13.876616\n",
      "4  2015-12-04  13.782220\n",
      "PFF.csv\n",
      "         Date  Adj Close\n",
      "0  2015-11-30  32.498180\n",
      "1  2015-12-01  32.565308\n",
      "2  2015-12-02  32.416126\n",
      "3  2015-12-03  32.291794\n",
      "4  2015-12-04  32.341515\n",
      "PFXF.csv\n",
      "         Date  Adj Close\n",
      "0  2015-11-30  16.100649\n",
      "1  2015-12-01  16.122187\n",
      "2  2015-12-02  16.022762\n",
      "3  2015-12-03  15.923350\n",
      "4  2015-12-04  15.923350\n",
      "SPFF.csv\n",
      "         Date  Adj Close\n",
      "0  2015-11-30  10.637997\n",
      "1  2015-12-01  10.647966\n",
      "2  2015-12-02  10.584156\n",
      "3  2015-12-03  10.552255\n",
      "4  2015-12-04  10.568208\n",
      "ULE.csv\n",
      "         Date        NAV\n",
      "0  03/15/2019  14.584440\n",
      "1  03/14/2019  14.537442\n",
      "2  03/13/2019  14.621051\n",
      "3  03/12/2019  14.529167\n",
      "4  03/11/2019  14.403578\n",
      "USDU.csv\n",
      "         Date      Nav\n",
      "0  03/15/2019  27.1822\n",
      "1  03/14/2019  27.2278\n",
      "2  03/13/2019  27.1473\n",
      "3  03/12/2019  27.2410\n",
      "4  03/11/2019  27.2980\n",
      "YCL.csv\n",
      "         Date        NAV\n",
      "0  03/15/2019  55.104685\n",
      "1  03/14/2019  54.901657\n",
      "2  03/13/2019  55.502899\n",
      "3  03/12/2019  55.335168\n",
      "4  03/11/2019  55.403469\n",
      "YCS.csv\n",
      "         Date        NAV\n",
      "0  03/15/2019  77.199178\n",
      "1  03/14/2019  77.481146\n",
      "2  03/13/2019  76.643701\n",
      "3  03/12/2019  76.870663\n",
      "4  03/11/2019  76.771444\n"
     ]
    }
   ],
   "source": [
    "for file in csv_list:\n",
    "\tdf = pd.read_csv(path + '\\\\' +file)\n",
    "\tcol_name = list(df.columns.values)\n",
    "\tif 'NAV' not in col_name:\n",
    "\t\tif 'Nav' in col_name:\n",
    "\t\t\tdf = df.loc[:, ['Date', 'Nav']]\n",
    "\t\telse:\n",
    "\t\t\tdf = df.loc[:, ['Date', 'Adj Close']]\n",
    "\t\n",
    "\t\t\t\n",
    "\telse:\n",
    "\t\tdf = df.loc[:, ['Date', 'NAV']]\n",
    "\tprint(file)\n",
    "\tprint(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
